{"meta":{"title":"Zequn's Blog","subtitle":"Stay hungry Stay Foolish","description":null,"author":"Zequn Song","url":"https://zequnsong.github.io","root":"/"},"pages":[{"title":"About","date":"2019-04-28T05:36:15.000Z","updated":"2019-04-28T05:38:46.363Z","comments":true,"path":"about/index.html","permalink":"https://zequnsong.github.io/about/index.html","excerpt":"","text":"I’m currently a graduate student at George Washington University. You can contact or know more about me by: Email: zsong73@gwu.edu GitHub: https://github.com/ZequnSong/ LinkedIn: https://www.linkedin.com/in/zequnsong"}],"posts":[{"title":"Uninformed Search","slug":"Uninformed-Search","date":"2019-05-03T06:05:11.000Z","updated":"2019-05-03T08:34:04.366Z","comments":true,"path":"2019/05/03/Uninformed-Search/","link":"","permalink":"https://zequnsong.github.io/2019/05/03/Uninformed-Search/","excerpt":"","text":"Uninformed Search means agent doesn’t know how close a state is to the goal state.Strategies that know whether one non-goal state is “more promising” than another are called Informed Search or Heuristic Search strategies; they are covered in next article. Breadth-First SearchThe root node is expanded first, then all the successors of the root node are expanded next, then their successors, and so on. In general, all the nodes are expanded at a given depth in the search tree before any nodes at the next level are expanded. Frontier: a FIFO queue 12345678910111213141516//-----------------------BREADTH-FIRST-SEARCH--------------------------function BREADTH-FIRST-SEARCH(problem) returns a solution, or failure node with STATE = problem.INITIAL-STATE, PATH-COST = 0 if problem.GOAL-TEST(node.STATE) then return SOLUTION(node) frontier = a FIFO queue with node as the only element explored = an empty set loop do if EMPTY?(frontier ) then return failure node = POP(frontier ) /* chooses the shallowest node in frontier */ add node.STATE to explored for each action in problem.ACTIONS(node.STATE) do child = CHILD-NODE(problem, node, action) if child.STATE is not in explored or frontier then //goal test is applied to each node when it is generated rather than when it is selected for expansion if problem.GOAL-TEST(child.STATE) then return SOLUTION(child) frontier = INSERT(child,frontier ) Evaluation Complete: if the shallowest goal node is at some finite depth d, breadth-first search will eventually find it after generating all shallower nodes (provided the branching factor b is finite). Not optimal: only optimal when the path cost is a non-decreasing function of the depth of the node. The most common such scenario is that all actions have the same cost. Time complexity:Imagine branching factor is $b$ (each state has $b$ successors).The root generates $b$ nodes at the first level.Each of these generates $b$ more nodes, for a total of $b^2$ at the second level.Each of these generates $b$ more nodes, yielding $b^3$ nodes at the third level, and so on.Suppose that the solution is at depth $s$.$$b + b^2 + b^3 + ··· + b^s = O(b^s)$$ BFS Space complexity:There will be $O(b^{s−1})$ nodes in the explored set and $O(b^s)$ nodes in the frontier. Depth-First SearchAlways expands the deepest node in the current frontier of the search tree. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded, they are dropped from the frontier, so then the search “backs up” to the next deepest node that still has unexplored successors Frontier: a LIFO queue Evaluation Complete: in finity state space. Not optimal: return the leftmost solution. Time complexity:Imagine branching factor is $b$.Suppose that maximum depth is $m$.Therefore, time complexity is $O(b^m)$, bigger than BFS. DFS Space complexity:Only needs to store a single path from the root to a leaf node, along with the remaining unexpanded sibling nodes for each node on the path. Once a node has been expanded, it can be removed from memory as soon as all its descendants have been fully explored.Therefore, DFS requires storage of only $O(bm)$ nodes. (if not use explored set) Depth Limited SearchThe embarrassing failure of DFS in infinite state spaces can be alleviated by supplying DFS with a predetermined depth limit $l$. That is, nodes at depth $l$ are treated as if they have no successors.DFS can be viewed as a special case of depth-limited search with $l=d$. Evaluation Not Complete: $l$ can be smaller than $s$. Not optimal: $l$ can be bigger than $d$. Time complexity: $O(b^l)$ Space complexity: $O(bl)$ Iterative Deepening SearchGet DFS’s space advantage with BFS’s time advantage. Repeat the DFS by gradually increasing the depth limit, until a goal is found. 123456//-----------------------BREADTH-FIRST-SEARCH--------------------------function ITERATIVE-DEEPENING-SEARCH(problem) returns a solution, or failure for depth = 0 to ∞ do result ← DEPTH-LIMITED-SEARCH(problem, depth) if result != cutoff then return result //the cutoff value indicates no solution within the depth limit. Evaluation Complete: same as BFS Not optimal: same as BFS Time complexity: $O(b^s)$asymptotically the same as BFSThere is some extra cost for generating the upper levels multiple times, but it is not large.For example, if $b = 10$ and $s = 5$, the numbers are$N(IDS) = 50 + 400 + 3, 000 + 20, 000 + 100, 000 = 123, 450$$N(BFS) = 10 + 100 + 1, 000 + 10, 000 + 100, 000 = 111, 110$ Space complexity: $O(bs)$ Uniform Cost SearchWhen all step costs are equal, breadth-first search is optimal because it always expands the shallowest unexpanded node.By a simple extension, we can find an algorithm that is optimal with any step-cost function.Instead of expanding the shallowest node, UCS expands the node n with the lowest g(n) which is path cost.This is done by storing the frontier as a priority queue ordered by g. Frontier: a priority queue (priority: cumulative cost g(n)) 12345678910111213141516//----------------------- UNIFORM-COST-SEARCH--------------------------function UNIFORM-COST-SEARCH(problem) returns a solution, or failure node ←a node with STATE = problem.INITIAL-STATE, PATH-COST = 0 frontier ← a priority queue ordered by PATH-COST, with node as the only element explored ← an empty set loop do if EMPTY?(frontier ) then return failure node ← POP(frontier ) /* chooses the lowest-cost node in frontier */ if problem.GOAL-TEST(node.STATE) then return SOLUTION(node) add node.STATE to explored for each action in problem.ACTIONS(node.STATE) do child ← CHILD-NODE(problem, node, action) if child.STATE is not in explored or frontier then frontier ← INSERT(child,frontier ) else if child.STATE is in frontier with higher PATH-COST then replace that frontier node with child Evaluation Complete: Not optimal: Time complexity: Space complexity:","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Uninformed & Informed Search","slug":"Artificial-Intelligence/Uninformed-Informed-Search","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Uninformed-Informed-Search/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"Tree Search","slug":"Tree-Search","date":"2019-04-28T06:37:58.000Z","updated":"2019-05-03T06:54:20.030Z","comments":true,"path":"2019/04/28/Tree-Search/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Tree-Search/","excerpt":"","text":"A problem-solving agent is one kind of goal-based agent. We already know that the characteristics of the environment dictate techniques for solving the problem. And the fast search techniques are suitable for known, observable, and deterministic environments. EnvironmentKnown: the agent knows which states are reached by each actionObservable: the agent always knows the current stateDeterministic: each action has exactly one outcome Before trying to solve the problem, we need to formulate the problem. Problem Formulation Initial state Actions &amp; Cost Transition function: Result(state, action) = next state State space: include every possible state Goal test: which determines whether a given state is a goal state Map of Rimania ExampleImagine an agent in the city of Arad, Romania. It wants to reach Bucharest. The environment is– known: the agent has a map of Romania;– observable: each city has a sign indicating its presence to arriving drivers;– deterministic: if agent chooses to drive from Arad to Sibiu, it does end up in Sibiu. The problem formulation is– Initial state: Arad;– Actions &amp; Cost: action == drive from city A to city B; cost == distance;– Transition function: Result(current city, action) = next city – known from the map;– State space: Cities on the map;– Goal test: Is state == Bucharest? Search TreeAfter formulated the problem, we now need to solve it. A solution to the problem above is a sequence of actions which transforms the initial state to a goal state. Search algorithms work by considering various possible action sequences through the search tree. Component of a search tree– root : initial state– nodes: states in state space– branches : actions– frontier (open list): a queue which contains all leaf nodes available for expansion– closed list: a set which remembers every expanded node. A Closed list is only needed when redundant paths are unavoidable, e.g. Arad -&gt; Sibiu -&gt; Arad …We need a closed list to avoid exploring redundant paths.The closed list should be implemented with a hash table to allow efficient checking forrepeated states. 123456789101112131415161718//------------informal description of the general tree-search---------------function TREE-SEARCH(problem) returns a solution, or failure initialize the frontier using the initial state of problem initialize the explored set to be empty loop do if the frontier is empty then return failure choose a leaf node and remove it from the frontier if the node contains a goal state then return the corresponding solution add the node to the explored set expand the chosen node, adding the resulting nodes to the frontier only if not in the frontier or explored set //---------------------- node of the search tree-------------------------function CHILD-NODE(problem, parent, action) returns a node return a node with STATE = problem.RESULT(parent.STATE, action), PARENT = parent, ACTION = action, PATH-COST = parent.PATH-COST + problem.STEP-COST(parent.STATE, action) The node has PARENT pointer, solution is the sequence of actions obtained by following parent pointers back to the root. ExampleFigure above shows the partial search trees for finding a route from Arad to Bucharest Component of the search tree– root : Arad– nodes (shaded): nodes that have been expanded;– nodes (outlined in bold): nodes that have been generated but not yet expanded;– nodes (dashed lines): nodes that have not yet been generated;– branches : parent node -&gt; child node;– frontier (open list): nodes outlined in bold;– explored set (closed list): a set which remembers every expanded node. Tree-Searchinitial frontier = { Arad };step1: remove Arad from frontier;step2: current city == goal city ? return solution : do step3.;step3: expand current city to adjacent cities: Sibiu, Timisoara, Zerind. Add them to frontier;step4: if frontier is not empty, choose a city to expand according to some strategy, and do step234 recurrently;step5: if frontier is not empty, return false. In fact, all search algorithms share this basic tree structure above, they vary primarily according to how they choose which state to expand next – the so-called search strategy. We have two different search strategies, Uninformed Search and Informed Search, which will be covered in next two articles. Evaluation Criteria for AlgorithmsBefore we get into the design of specific search strategies, we need to consider the criteria that might be used to choose among them. We can evaluate an algorithm’s performance infour ways: Completeness: Is the algorithm guaranteed to find a solution when there is one? Optimality: Does the strategy find the optimal solution? Time complexity: How long does it take to find a solution? Space complexity: How much memory is needed to perform the search? In AI, complexity is expressed in terms of three quantities: $b$: the branching factor or maximum number of successors of any node; $d$: the depth of the shallowest goal node (i.e., the number of steps along the path from the root); $m$: the maximum length of any path in the state space. Time is often measured in terms of the number of nodes generated during the search.Space in terms of the maximum number of nodes stored in memory. Source of pictures for this article:Russell and Norvig (2010). Artificial Intelligence: A Modern Approach.","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Uninformed & Informed Search","slug":"Artificial-Intelligence/Uninformed-Informed-Search","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Uninformed-Informed-Search/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"Introduction to AI","slug":"Introduction-to-AI","date":"2019-04-28T06:09:22.000Z","updated":"2019-04-28T06:12:16.317Z","comments":true,"path":"2019/04/28/Introduction-to-AI/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Introduction-to-AI/","excerpt":"","text":"What is AI? Nowadays, AI means designing a rational agent, which could act rationlly to choose the action that maximizes its expected utility. AgentAn agent is an entity that perceives and acts. A rational agent selects actions that maximize its expected utility. Characteristics of the percepts, environment, and action space dictate techniques for selecting rational actions. An agent needs sensors to sense the information of the environment, and also needs actuators to take actions based on perceived information. GoalThis and following articles are about general AI techniques for a variety of problem types and learning to recognize when and how a new problem can be solved with an existing technique. The following articles will cover AI in two parts: Part I: Making Decisions Uninformed and Informed Search Constraint Satisfaction Problem Adversarial and Uncertain Search Part II: Reasoning under Uncertainty Markov Decision Problem Reinforcement Learning Markov Model &amp; Hidden Markov Model","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Introduction to AI","slug":"Artificial-Intelligence/Introduction-to-AI","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Introduction-to-AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"TagPlugins Test","slug":"TagPlugins-Test","date":"2019-04-28T06:08:58.000Z","updated":"2019-04-28T06:24:53.380Z","comments":true,"path":"2019/04/28/TagPlugins-Test/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/TagPlugins-Test/","excerpt":"","text":"In Hexo, Tag Plugins are used for inserting specific content into the article. Let me show you how it works here. Quote123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; Example: Use all the parameters Zequn Song, A book of GeniusZequn's blog Don’t worry, Tweet happy. (Quote from twitter) @Twittertwitter.com/Twitter/status/1119338115989213185 Code Block123&#123;% codeblock [lang:language] [description] [source_link for description]%&#125;code&#123;% endcodeblock %&#125; Example: test-java123public static void display()&#123; System.out.println(\"Test for code block\");&#125; jsFiddle1&#123;% jsfiddle shorttag [tabs] [skin] [width] [height] %&#125; GistEmbed with js: Embed with tag plugins: Gist Preview on bl.ocks: https://bl.ocks.org/ZequnSong/08f61c6d1c146014a297eadf486bacef iframecan be used to embed web, video, music image youtube vimeo","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://zequnsong.github.io/categories/Hexo/"},{"name":"Tag Plugins","slug":"Hexo/Tag-Plugins","permalink":"https://zequnsong.github.io/categories/Hexo/Tag-Plugins/"}],"tags":[]}]}