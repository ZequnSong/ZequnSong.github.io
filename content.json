{"meta":{"title":"Zequn's Blog","subtitle":"Stay hungry Stay Foolish","description":null,"author":"Zequn Song","url":"https://zequnsong.github.io","root":"/"},"pages":[{"title":"About","date":"2019-04-28T05:36:15.000Z","updated":"2019-04-28T05:38:46.363Z","comments":true,"path":"about/index.html","permalink":"https://zequnsong.github.io/about/index.html","excerpt":"","text":"I’m currently a graduate student at George Washington University. You can contact or know more about me by: Email: zsong73@gwu.edu GitHub: https://github.com/ZequnSong/ LinkedIn: https://www.linkedin.com/in/zequnsong"}],"posts":[{"title":"Tree Search","slug":"Tree-Search","date":"2019-04-28T06:37:58.000Z","updated":"2019-04-28T06:38:03.343Z","comments":true,"path":"2019/04/28/Tree-Search/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Tree-Search/","excerpt":"","text":"A problem-solving agent is one kind of goal-based agent. We already know that the characteristics of the environment dictate techniques for solving the problem. And the fast search techniques are suitable for known, observable, and deterministic environments. EnvironmentKnown: the agent knows which states are reached by each actionObservable: the agent always knows the current stateDeterministic: each action has exactly one outcome Before trying to solve the problem, we need to formulate the problem. Problem Formulation Initial state Actions &amp; Cost Transition function: Result(state, action) = next state State space: include every possible state Goal test: which determines whether a given state is a goal state Map of Rimania ExampleImagine an agent in the city of Arad, Romania. It wants to reach Bucharest. The environment is– known: the agent has a map of Romania;– observable: each city has a sign indicating its presence to arriving drivers;– deterministic: if agent chooses to drive from Arad to Sibiu, it does end up in Sibiu. The problem formulation is– Initial state: Arad;– Actions &amp; Cost: action == drive from city A to city B; cost == distance;– Transition function: Result(current city, action) = next city – known from the map;– State space: Cities on the map;– Goal test: Is state == Bucharest? Search TreeAfter formulated the problem, we now need to solve it. A solution to the problem above is a sequence of actions which transforms the initial state to a goal state. Search algorithms work by considering various possible action sequences through the search tree. Component of a search tree– root : initial state– nodes: states in state space– branches : actions– frontier (open list): a queue which contains all leaf nodes available for expansion– closed list: a set which remembers every expanded node. A Closed list is only needed when redundant paths are unavoidable, e.g. Arad -&gt; Sibiu -&gt; Arad …We need a closed list to avoid exploring redundant paths.The closed list should be implemented with a hash table to allow efficient checking forrepeated states. 123456789101112131415161718//------------informal description of the general tree-search---------------function TREE-SEARCH(problem) returns a solution, or failure initialize the frontier using the initial state of problem initialize the explored set to be empty loop do if the frontier is empty then return failure choose a leaf node and remove it from the frontier if the node contains a goal state then return the corresponding solution add the node to the explored set expand the chosen node, adding the resulting nodes to the frontier only if not in the frontier or explored set //---------------------- node of the search tree-------------------------function CHILD-NODE(problem, parent, action) returns a node return a node with STATE = problem.RESULT(parent.STATE, action), PARENT = parent, ACTION = action, PATH-COST = parent.PATH-COST + problem.STEP-COST(parent.STATE, action) The node has PARENT pointer, solution is the sequence of actions obtained by following parent pointers back to the root. ExampleFigure above shows the partial search trees for finding a route from Arad to Bucharest Component of the search tree– root : Arad– nodes (shaded): nodes that have been expanded;– nodes (outlined in bold): nodes that have been generated but not yet expanded;– nodes (dashed lines): nodes that have not yet been generated;– branches : parent node -&gt; child node;– frontier (open list): nodes outlined in bold;– explored set (closed list): a set which remembers every expanded node. Tree-Searchinitial frontier = { Arad };step1: remove Arad from frontier;step2: current city == goal city ? return solution : do step3.;step3: expand current city to adjacent cities: Sibiu, Timisoara, Zerind. Add them to frontier;step4: if frontier is not empty, choose a city to expand according to some strategy, and do step234 recurrently;step5: if frontier is not empty, return false. In fact, all search algorithms share this basic tree structure above, they vary primarily according to how they choose which state to expand next – the so-called search strategy. We have two different search strategy, Uninformed Search and Informed Search, which will be covered in next two articles. Evaluation Criteria for AlgorithmsBefore we get into the design of specific search strategies, we need to consider the criteria that might be used to choose among them. We can evaluate an algorithm’s performance infour ways: Completeness: Is the algorithm guaranteed to find a solution when there is one? Optimality: Does the strategy find the optimal solution? Time complexity: How long does it take to find a solution? Space complexity: How much memory is needed to perform the search? In AI, complexity is expressed in terms of three quantities: b: the branching factor or maximum number of successors of any node; d: the depth of the shallowest goal node (i.e., the number of steps along the path from the root); m: the maximum length of any path in the state space. Time is often measured in terms of the number of nodes generated during the search.Space in terms of the maximum number of nodes stored in memory. Source of pictures for this article:Russell and Norvig (2010). Artificial Intelligence: A Modern Approach.","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Uninformed & Informed Search","slug":"Artificial-Intelligence/Uninformed-Informed-Search","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Uninformed-Informed-Search/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"Introduction to AI","slug":"Introduction-to-AI","date":"2019-04-28T06:09:22.000Z","updated":"2019-04-28T06:12:16.317Z","comments":true,"path":"2019/04/28/Introduction-to-AI/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Introduction-to-AI/","excerpt":"","text":"What is AI? Nowadays, AI means designing a rational agent, which could act rationlly to choose the action that maximizes its expected utility. AgentAn agent is an entity that perceives and acts. A rational agent selects actions that maximize its expected utility. Characteristics of the percepts, environment, and action space dictate techniques for selecting rational actions. An agent needs sensors to sense the information of the environment, and also needs actuators to take actions based on perceived information. GoalThis and following articles are about general AI techniques for a variety of problem types and learning to recognize when and how a new problem can be solved with an existing technique. The following articles will cover AI in two parts: Part I: Making Decisions Uninformed and Informed Search Constraint Satisfaction Problem Adversarial and Uncertain Search Part II: Reasoning under Uncertainty Markov Decision Problem Reinforcement Learning Markov Model &amp; Hidden Markov Model","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Introduction to AI","slug":"Artificial-Intelligence/Introduction-to-AI","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Introduction-to-AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"TagPlugins Test","slug":"TagPlugins-Test","date":"2019-04-28T06:08:58.000Z","updated":"2019-04-28T06:24:53.380Z","comments":true,"path":"2019/04/28/TagPlugins-Test/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/TagPlugins-Test/","excerpt":"","text":"In Hexo, Tag Plugins are used for inserting specific content into the article. Let me show you how it works here. Quote123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; Example: Use all the parameters Zequn Song, A book of GeniusZequn's blog Don’t worry, Tweet happy. (Quote from twitter) @Twittertwitter.com/Twitter/status/1119338115989213185 Code Block123&#123;% codeblock [lang:language] [description] [source_link for description]%&#125;code&#123;% endcodeblock %&#125; Example: test-java123public static void display()&#123; System.out.println(\"Test for code block\");&#125; jsFiddle1&#123;% jsfiddle shorttag [tabs] [skin] [width] [height] %&#125; GistEmbed with js: Embed with tag plugins: Gist Preview on bl.ocks: https://bl.ocks.org/ZequnSong/08f61c6d1c146014a297eadf486bacef iframecan be used to embed web, video, music image youtube vimeo","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://zequnsong.github.io/categories/Hexo/"},{"name":"Tag Plugins","slug":"Hexo/Tag-Plugins","permalink":"https://zequnsong.github.io/categories/Hexo/Tag-Plugins/"}],"tags":[]}]}