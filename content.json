{"meta":{"title":"Zequn's Blog","subtitle":"Stay hungry Stay Foolish","description":null,"author":"Zequn Song","url":"https://zequnsong.github.io","root":"/"},"pages":[{"title":"About","date":"2019-04-28T05:36:15.000Z","updated":"2019-04-28T05:38:46.363Z","comments":true,"path":"about/index.html","permalink":"https://zequnsong.github.io/about/index.html","excerpt":"","text":"I’m currently a graduate student at George Washington University. You can contact or know more about me by: Email: zsong73@gwu.edu GitHub: https://github.com/ZequnSong/ LinkedIn: https://www.linkedin.com/in/zequnsong"}],"posts":[{"title":"Uninformed Search","slug":"Uninformed-Search","date":"2019-05-03T06:05:11.000Z","updated":"2019-05-04T08:07:09.588Z","comments":true,"path":"2019/05/03/Uninformed-Search/","link":"","permalink":"https://zequnsong.github.io/2019/05/03/Uninformed-Search/","excerpt":"","text":"Uninformed Search means agent doesn’t know how close a state is to the goal state.Strategies that know whether one non-goal state is “more promising” than another are called Informed Search or Heuristic Search strategies; they are covered in next article. Breadth-First SearchThe root node is expanded first, then all the successors of the root node are expanded next, then their successors, and so on. In general, all the nodes are expanded at a given depth in the search tree before any nodes at the next level are expanded. Frontier: a FIFO queue 12345678910111213141516//-----------------------BREADTH-FIRST-SEARCH--------------------------function BREADTH-FIRST-SEARCH(problem) returns a solution, or failure node with STATE = problem.INITIAL-STATE, PATH-COST = 0 if problem.GOAL-TEST(node.STATE) then return SOLUTION(node) frontier = a FIFO queue with node as the only element explored = an empty set loop do if EMPTY?(frontier ) then return failure node = POP(frontier ) /* chooses the shallowest node in frontier */ add node.STATE to explored for each action in problem.ACTIONS(node.STATE) do child = CHILD-NODE(problem, node, action) if child.STATE is not in explored or frontier then //goal test is applied to each node when it is generated rather than when it is selected for expansion if problem.GOAL-TEST(child.STATE) then return SOLUTION(child) frontier = INSERT(child,frontier ) Evaluation Complete:If the shallowest goal node is at some finite depth d, breadth-first search will eventually find it after generating all shallower nodes (provided the branching factor b is finite). Not optimal:Only optimal when the path cost is a non-decreasing function of the depth of the node. The most common such scenario is that all actions have the same cost. Time complexity:Imagine branching factor is $b$ (each state has $b$ successors).The root generates $b$ nodes at the first level.Each of these generates $b$ more nodes, for a total of $b^2$ at the second level.Each of these generates $b$ more nodes, yielding $b^3$ nodes at the third level, and so on.Suppose that the solution is at depth $s$.$$b + b^2 + b^3 + ··· + b^s = O(b^s)$$ BFS Space complexity:There will be $O(b^{s−1})$ nodes in the explored set and $O(b^s)$ nodes in the frontier. Depth-First SearchAlways expands the deepest node in the current frontier of the search tree. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded, they are dropped from the frontier, so then the search “backs up” to the next deepest node that still has unexplored successors Frontier: a LIFO queue Evaluation The properties of DFS strongly on whether the graph-search or tree-search version is used Complete:Complete by graph-search if finite state space.Not Complete by treee-search, maybe follow the loop forever. Not optimal:Return the leftmost solution. Time complexity:Imagine branching factor is $b$.Suppose that maximum depth is $m$.Therefore, time complexity is $O(b^m)$, bigger than BFS.In tree search version, $m$ may be much larger than $d$ (the depth of shallowest solution). DFS Space complexity:Only needs to store a single path from the root to a leaf node, along with the remaining unexpanded sibling nodes for each node on the path. Once a node has been expanded, it can be removed from memory as soon as all its descendants have been fully explored.Therefore, DFS requires storage of only $O(bm)$ nodes. (if not use explored set) Depth Limited SearchThe embarrassing failure of DFS in infinite state spaces can be alleviated by supplying DFS with a predetermined depth limit $l$. That is, nodes at depth $l$ are treated as if they have no successors.DFS can be viewed as a special case of depth-limited search with $l=d$. Evaluation Not Complete: $l$ can be smaller than $s$. Not optimal: $l$ can be bigger than $d$. Time complexity: $O(b^l)$ Space complexity: $O(bl)$ Iterative Deepening SearchGet DFS’s space advantage with BFS’s time advantage. Repeat the DFS by gradually increasing the depth limit, until a goal is found. 123456//-----------------------BREADTH-FIRST-SEARCH--------------------------function ITERATIVE-DEEPENING-SEARCH(problem) returns a solution, or failure for depth = 0 to ∞ do result ← DEPTH-LIMITED-SEARCH(problem, depth) if result != cutoff then return result //the cutoff value indicates no solution within the depth limit. Limit 0 is root node.Run a DFS with depth limit 1. If no solution…Run a DFS with depth limit 2. If no solution…Run a DFS with depth limit 3. … Evaluation Complete: same as BFS Not optimal: same as BFS Time complexity: $O(b^s)$asymptotically the same as BFSThere is some extra cost for generating the upper levels multiple times, but it is not large.For example, if $b = 10$ and $s = 5$, the numbers are$N(IDS) = 50 + 400 + 3000 + 20000 + 100000 = 123450$$N(BFS) = 10 + 100 + 1000 + 10000 + 100000 = 111110$ Space complexity: $O(bs)$ Uniform Cost SearchBFS is only optima with non-decreasing cost function.But UCS can find the least-cost(optimal) path with any step-cost function.Instead of expanding the shallowest node, UCS expands the node n with the lowest $g(n)$ (which is path cost). There are two other significant differences from breadth-first search. The first is that the goal test is applied to a node when it is selected for expansion rather than when it is first generated. The reason is that the first goal node that is generated may be on a suboptimal path. The second difference is that a test is added in the end in case a better path is found to a node currently on the frontier Frontier: a priority queue (ordered by cumulative cost g(n)) 12345678910111213141516//----------------------- UNIFORM-COST-SEARCH--------------------------function UNIFORM-COST-SEARCH(problem) returns a solution, or failure node with STATE = problem.INITIAL-STATE, PATH-COST = 0 frontier = a priority queue ordered by PATH-COST, with node as the only element explored = an empty set loop do if EMPTY?(frontier ) then return failure node = POP(frontier ) /* chooses the lowest-cost node in frontier */ if problem.GOAL-TEST(node.STATE) then return SOLUTION(node) //different goaltest location add node.STATE to explored for each action in problem.ACTIONS(node.STATE) do child = CHILD-NODE(problem, node, action) if child.STATE is not in explored or frontier then frontier ← INSERT(child,frontier ) else if child.STATE is in frontier with higher PATH-COST then replace that frontier node with child Example The goal is to get from Sibiu to Bucharest.Frontier={ Sibiu-0 } The successors of Sibiu are Rimnicu Vilcea and Fagaras, with costs 80 and 99, respectively.Frontier={ Rimnicu Vilcea-80, Fagaras-99 } The least-cost node, Rimnicu Vilcea, is expanded.adding Pitesti with cost 80 + 97 = 177.Frontier={ Fagaras-99, Pitesti-177 } The least-cost node is now Fagaras, so it is expanded, adding Bucharest with cost 99 + 211 = 310.Frontier={ Pitesti-177, Bucharest-310 } Now a goal node has been generated, but UCS keeps going, no goal test now.Choosing Pitesti for expansion and adding a second path to Bucharest with cost 80+ 97+ 101 = 278.Frontier={ Bucharest(2)-278, Bucharest(1)-310 } Choosing Bucharest(2), goal test now, the node to expand is goal state Bucharest with g-cost 278, the solution is returned. EvaluationUCS is guided by path costs rather than depths, so its complexity is not easily characterized in terms of $b$ and $d$.Define some new variables:$C^*$ is the cost for the optimal plan that reach the goal.$\\epsilon$ is the minimum cost for each actionTherefore, we will go at most $C^*/\\epsilon$ deep. Complete:As long as there is a lower bound of the cost of each action ($\\epsilon$ exist and $\\epsilon&gt;0$)UCS is a generalization of Breadth First Search in the sense that it takes costs of each edge into account. Optimal:Whenever UCS selects a node n for expansion, the optimal path to that node has been found, because our expand strategy is expands the node with the lowest path cost g(n)Then, because step costs are non-negative, paths never get shorter as nodes are added.These two facts together imply that UCS expands nodes in order of their optimal path cost.Hence, the first goal node selected for expansion must be the optimal solution. Time complexity: $O(b^{C^*/\\epsilon})$Longer than BFS. BFS stops as soon as it generates a goal, whereas UCS examines all the nodes at the goal’s depth to see if one has a lower cost; thus UCS does strictly more work by expanding nodes at depth d unnecessarily. Space complexity: $O(b^{C^*/\\epsilon})$ roughly the last tier Conceptually, all the search algorithms above are the same except for frontier strategies, and all frontier are priority queues (priority means strategy).","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Uninformed & Informed Search","slug":"Artificial-Intelligence/Uninformed-Informed-Search","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Uninformed-Informed-Search/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"Tree Search","slug":"Tree-Search","date":"2019-04-28T06:37:58.000Z","updated":"2019-05-04T07:53:25.462Z","comments":true,"path":"2019/04/28/Tree-Search/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Tree-Search/","excerpt":"","text":"A problem-solving agent is one kind of goal-based agent. We already know that the characteristics of the environment dictate techniques for solving the problem. And the fast search techniques are suitable for known, observable, and deterministic environments. EnvironmentKnown: the agent knows which states are reached by each actionObservable: the agent always knows the current stateDeterministic: each action has exactly one outcome Before trying to solve the problem, we need to formulate the problem. Problem Formulation Initial state Actions &amp; Cost Transition function: Result(state, action) = next state State space: include every possible state Goal test: which determines whether a given state is a goal state Map of Rimania ExampleImagine an agent in the city of Arad, Romania. It wants to reach Bucharest. The environment is– known: the agent has a map of Romania;– observable: each city has a sign indicating its presence to arriving drivers;– deterministic: if agent chooses to drive from Arad to Sibiu, it does end up in Sibiu. The problem formulation is– Initial state: Arad;– Actions &amp; Cost: action == drive from city A to city B; cost == distance;– Transition function: Result(current city, action) = next city – known from the map;– State space: Cities on the map;– Goal test: Is state == Bucharest? After formulated the problem, we now need to solve it. Tree Search Component of a search tree– root : initial state– nodes: states in state space– branches : actions– frontier (open list): a queue which contains all leaf nodes available for expansion 123456789101112131415//------------informal description of the general tree-search---------------function TREE-SEARCH(problem) returns a solution, or failure initialize the frontier using the initial state of problem loop do if the frontier is empty then return failure choose a leaf node and remove it from the frontier if the node contains a goal state then return the corresponding solution expand the chosen node, adding the resulting nodes to the frontier //---------------------- node of the search tree-------------------------function CHILD-NODE(problem, parent, action) returns a node return a node with STATE = problem.RESULT(parent.STATE, action), PARENT = parent, ACTION = action, PATH-COST = parent.PATH-COST + problem.STEP-COST(parent.STATE, action) The node has PARENT pointer, solution is the sequence of actions obtained by following parent pointers back to the root. ExampleFigure above shows the partial search trees for finding a route from Arad to Bucharest Component of the search tree– root : Arad– nodes (shaded): nodes that have been expanded;– nodes (outlined in bold): nodes that have been generated but not yet expanded;– nodes (dashed lines): nodes that have not yet been generated;– branches : parent node -&gt; child node;– frontier (open list): nodes outlined in bold; Tree-Searchinitial frontier = { Arad };step1: remove Arad from frontier;step2: current city == goal city ? return solution : do step3.;step3: expand current city to adjacent cities: Sibiu, Timisoara, Zerind. Add them to frontier;step4: if frontier is not empty, choose a city to expand according to some strategy, and do step234 recurrently;step5: if frontier is not empty, return false. Graph SearchSometimes redundant paths are unavoidable, e.g. Arad -&gt; Sibiu -&gt; Arad …The way to avoid exploring redundant paths is to remember where one has been.To do this, we augment the TREE-SEARCH algorithm with a data structure called the explored set (also known as the closed list), which remembers every expanded node.Newly generated nodes that match previously generated nodes—ones in the explored set or the frontier—can be discarded instead of being added to the frontier. The new algorithm, called GRAPH-SEARCH. The closed list should be implemented with a hash table to allow efficient checking for repeated states. 1234567891011------------informal description of the general graphe-search---------------function GRAPH-SEARCH(problem) returns a solution, or failure initialize the frontier using the initial state of problem initialize the explored set to be empty loop do if the frontier is empty then return failure choose a leaf node and remove it from the frontier if the node contains a goal state then return the corresponding solution add the node to the explored set expand the chosen node, adding the resulting nodes to the frontier only if not in the frontier or explored set In fact, all search algorithms share the structures above, they vary primarily according to how they choose which state to expand next – the so-called search strategy. We have two different search strategies, Uninformed Search and Informed Search, which will be covered in next two articles. Evaluation Criteria for AlgorithmsBefore we get into the design of specific search strategies, we need to consider the criteria that might be used to choose among them. We can evaluate an algorithm’s performance infour ways: Completeness: Is the algorithm guaranteed to find a solution when there is one? Optimality: Does the strategy find the optimal solution? Time complexity: How long does it take to find a solution? Space complexity: How much memory is needed to perform the search? In AI, complexity is expressed in terms of three quantities: $b$: the branching factor or maximum number of successors of any node; $d$: the depth of the shallowest goal node (i.e., the number of steps along the path from the root); $m$: the maximum length of any path in the state space. Time is often measured in terms of the number of nodes generated during the search.Space in terms of the maximum number of nodes stored in memory. Source of pictures for this article:Russell and Norvig (2010). Artificial Intelligence: A Modern Approach.","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Uninformed & Informed Search","slug":"Artificial-Intelligence/Uninformed-Informed-Search","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Uninformed-Informed-Search/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"Introduction to AI","slug":"Introduction-to-AI","date":"2019-04-28T06:09:22.000Z","updated":"2019-04-28T06:12:16.317Z","comments":true,"path":"2019/04/28/Introduction-to-AI/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/Introduction-to-AI/","excerpt":"","text":"What is AI? Nowadays, AI means designing a rational agent, which could act rationlly to choose the action that maximizes its expected utility. AgentAn agent is an entity that perceives and acts. A rational agent selects actions that maximize its expected utility. Characteristics of the percepts, environment, and action space dictate techniques for selecting rational actions. An agent needs sensors to sense the information of the environment, and also needs actuators to take actions based on perceived information. GoalThis and following articles are about general AI techniques for a variety of problem types and learning to recognize when and how a new problem can be solved with an existing technique. The following articles will cover AI in two parts: Part I: Making Decisions Uninformed and Informed Search Constraint Satisfaction Problem Adversarial and Uncertain Search Part II: Reasoning under Uncertainty Markov Decision Problem Reinforcement Learning Markov Model &amp; Hidden Markov Model","categories":[{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/"},{"name":"Introduction to AI","slug":"Artificial-Intelligence/Introduction-to-AI","permalink":"https://zequnsong.github.io/categories/Artificial-Intelligence/Introduction-to-AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://zequnsong.github.io/tags/AI/"}]},{"title":"TagPlugins Test","slug":"TagPlugins-Test","date":"2019-04-28T06:08:58.000Z","updated":"2019-04-28T06:24:53.380Z","comments":true,"path":"2019/04/28/TagPlugins-Test/","link":"","permalink":"https://zequnsong.github.io/2019/04/28/TagPlugins-Test/","excerpt":"","text":"In Hexo, Tag Plugins are used for inserting specific content into the article. Let me show you how it works here. Quote123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; Example: Use all the parameters Zequn Song, A book of GeniusZequn's blog Don’t worry, Tweet happy. (Quote from twitter) @Twittertwitter.com/Twitter/status/1119338115989213185 Code Block123&#123;% codeblock [lang:language] [description] [source_link for description]%&#125;code&#123;% endcodeblock %&#125; Example: test-java123public static void display()&#123; System.out.println(\"Test for code block\");&#125; jsFiddle1&#123;% jsfiddle shorttag [tabs] [skin] [width] [height] %&#125; GistEmbed with js: Embed with tag plugins: Gist Preview on bl.ocks: https://bl.ocks.org/ZequnSong/08f61c6d1c146014a297eadf486bacef iframecan be used to embed web, video, music image youtube vimeo","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://zequnsong.github.io/categories/Hexo/"},{"name":"Tag Plugins","slug":"Hexo/Tag-Plugins","permalink":"https://zequnsong.github.io/categories/Hexo/Tag-Plugins/"}],"tags":[]}]}